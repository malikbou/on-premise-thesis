{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b952b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from ragas.testset import TestsetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e9e4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6142e822ec584f64a1ed7944744bf790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0987926aab4a62a15808103b6287fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34746f6fea54404dad9a377f1ff8da0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '546a22'. Skipping!\n",
      "Property 'summary' already exists in node '9a23f2'. Skipping!\n",
      "Property 'summary' already exists in node '44a4e5'. Skipping!\n",
      "Property 'summary' already exists in node '1cc2a0'. Skipping!\n",
      "Property 'summary' already exists in node 'f3142e'. Skipping!\n",
      "Property 'summary' already exists in node '1f42e1'. Skipping!\n",
      "Property 'summary' already exists in node '802887'. Skipping!\n",
      "Property 'summary' already exists in node 'c0a483'. Skipping!\n",
      "Property 'summary' already exists in node 'a4a900'. Skipping!\n",
      "Property 'summary' already exists in node 'bb635a'. Skipping!\n",
      "Property 'summary' already exists in node '4cda86'. Skipping!\n",
      "Property 'summary' already exists in node '9c668c'. Skipping!\n",
      "Property 'summary' already exists in node '43a9d9'. Skipping!\n",
      "Property 'summary' already exists in node '722caa'. Skipping!\n",
      "Property 'summary' already exists in node '3b5035'. Skipping!\n",
      "Property 'summary' already exists in node '76598a'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e877c4e3785f4253a10c4ff8421df22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544508be2cd74885822c68e3f94cd3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node '546a22'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '1f42e1'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '1cc2a0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '44a4e5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '9a23f2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c0a483'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f3142e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '802887'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '722caa'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a4a900'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'bb635a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '9c668c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '76598a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4cda86'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '43a9d9'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3b5035'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b0559e81ac4ab7bcd5e2c56d5357d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebf6b39f54045f6bfd04607e2971de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa6b71e539847f7af86db49b09b8bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1eeca9b36a545d0927161e34e196987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = \"data/sts-student-handbook.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()\n",
    "docs = loader.load()\n",
    "\n",
    "# print(docs)\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-3.5-turbo-16k\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd48a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_sample=SingleTurnSample(user_input='What are the key responsibilities of an Academic Assessment Coordinator in ensuring accurate grading of student work?', retrieved_contexts=None, reference_contexts=[], response=None, multi_responses=None, reference='The key responsibilities of an Academic Assessment Coordinator in ensuring accurate grading of student work include ensuring marking guidelines are followed for individual items of assessment and providing criteria for grading student work.', rubrics=None) synthesizer_name='multi_hop_abstract_query_synthesizer'\n",
      "eval_sample=SingleTurnSample(user_input='What are the key criteria outlined by the departmental guidelines for assessing student work?', retrieved_contexts=None, reference_contexts=[], response=None, multi_responses=None, reference='The key criteria outlined by the departmental guidelines for assessing student work include factors such as originality, depth of analysis, adherence to academic standards, and overall coherence of arguments presented in the work.', rubrics=None) synthesizer_name='multi_hop_abstract_query_synthesizer'\n",
      "eval_sample=SingleTurnSample(user_input='There are no themes available for combination in this context.', retrieved_contexts=None, reference_contexts=[], response=None, multi_responses=None, reference='No concepts available for combination.', rubrics=None) synthesizer_name='multi_hop_abstract_query_synthesizer'\n"
     ]
    }
   ],
   "source": [
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': 'What are the key responsibilities of an Academic Assessment Coordinator in ensuring accurate grading of student work?', 'reference_contexts': [], 'reference': 'The key responsibilities of an Academic Assessment Coordinator in ensuring accurate grading of student work include ensuring marking guidelines are followed for individual items of assessment and providing criteria for grading student work.', 'synthesizer_name': 'multi_hop_abstract_query_synthesizer'}\n",
      "{'user_input': 'What are the key criteria outlined by the departmental guidelines for assessing student work?', 'reference_contexts': [], 'reference': 'The key criteria outlined by the departmental guidelines for assessing student work include factors such as originality, depth of analysis, adherence to academic standards, and overall coherence of arguments presented in the work.', 'synthesizer_name': 'multi_hop_abstract_query_synthesizer'}\n",
      "{'user_input': 'There are no themes available for combination in this context.', 'reference_contexts': [], 'reference': 'No concepts available for combination.', 'synthesizer_name': 'multi_hop_abstract_query_synthesizer'}\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.to_list():\n",
    "    print(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e769125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully generated and saved Q&A pairs to data/testset.json\n"
     ]
    }
   ],
   "source": [
    "# 7. Save the testset\n",
    "output_path = \"data/testset.json\"\n",
    "\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(dataset.to_pandas().to_json(), f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSuccessfully generated and saved Q&A pairs to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5ca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"user_input\":{\"0\":\"What are the key responsibilities of an Academic Assessment Coordinator in ensuring accurate grading of student work?\",\"1\":\"What are the key criteria outlined by the departmental guidelines for assessing student work?\",\"2\":\"There are no themes available for combination in this context.\"},\"reference_contexts\":{\"0\":[],\"1\":[],\"2\":[]},\"reference\":{\"0\":\"The key responsibilities of an Academic Assessment Coordinator in ensuring accurate grading of student work include ensuring marking guidelines are followed for individual items of assessment and providing criteria for grading student work.\",\"1\":\"The key criteria outlined by the departmental guidelines for assessing student work include factors such as originality, depth of analysis, adherence to academic standards, and overall coherence of arguments presented in the work.\",\"2\":\"No concepts available for combination.\"},\"synthesizer_name\":{\"0\":\"multi_hop_abstract_query_synthesizer\",\"1\":\"multi_hop_abstract_query_synthesizer\",\"2\":\"multi_hop_abstract_query_synthesizer\"}}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas().to_json()\n",
    "\n",
    "output_path = \"data/testset.json\"\n",
    "\n",
    "print(\"Testset generation complete. Converting to desired format...\")\n",
    "# 6. Convert to our desired JSON format\n",
    "output_data = [\n",
    "    {\"user_input\": item['question'], \"reference\": item['ground_truth']}\n",
    "    for item in dataset.to_list()\n",
    "]\n",
    "\n",
    "# 7. Save the testset\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSuccessfully generated and saved {len(output_data)} Q&A pairs to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9875d4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset generation complete. Converting to desired format...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTestset generation complete. Converting to desired format...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 6. Convert to our desired JSON format\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m output_data = \u001b[43m[\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreference\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 7. Save the testset\u001b[39;00m\n\u001b[32m     11\u001b[39m os.makedirs(os.path.dirname(output_path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTestset generation complete. Converting to desired format...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 6. Convert to our desired JSON format\u001b[39;00m\n\u001b[32m      5\u001b[39m output_data = [\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33muser_input\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mreference\u001b[39m\u001b[33m\"\u001b[39m: item[\u001b[33m'\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m'\u001b[39m]}\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dataset.to_list()\n\u001b[32m      8\u001b[39m ]\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 7. Save the testset\u001b[39;00m\n\u001b[32m     11\u001b[39m os.makedirs(os.path.dirname(output_path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyError\u001b[39m: 'question'"
     ]
    }
   ],
   "source": [
    "output_path = \"data/testset.json\"\n",
    "\n",
    "print(\"Testset generation complete. Converting to desired format...\")\n",
    "# 6. Convert to our desired JSON format\n",
    "output_data = [\n",
    "    {\"user_input\": item['question'], \"reference\": item['ground_truth']}\n",
    "    for item in dataset.to_list()\n",
    "]\n",
    "\n",
    "# 7. Save the testset\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSuccessfully generated and saved {len(output_data)} Q&A pairs to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868214c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Testset' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m     reference = sample_str[reference_start:reference_end]\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33muser_input\u001b[39m\u001b[33m\"\u001b[39m: user_input, \u001b[33m\"\u001b[39m\u001b[33mreference\u001b[39m\u001b[33m\"\u001b[39m: reference}\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m output_data = \u001b[43m[\u001b[49m\u001b[43msample_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Save to JSON\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mdata/testset.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      9\u001b[39m     reference = sample_str[reference_start:reference_end]\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33muser_input\u001b[39m\u001b[33m\"\u001b[39m: user_input, \u001b[33m\"\u001b[39m\u001b[33mreference\u001b[39m\u001b[33m\"\u001b[39m: reference}\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m output_data = [\u001b[43msample_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Save to JSON\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mdata/testset.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36msample_to_json\u001b[39m\u001b[34m(sample_str)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msample_to_json\u001b[39m(sample_str):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Extract user_input and reference from the sample string\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     user_input_start = \u001b[43msample_str\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33muser_input=\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m) + \u001b[38;5;28mlen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33muser_input=\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     user_input_end = sample_str.find(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, user_input_start)\n\u001b[32m      5\u001b[39m     user_input = sample_str[user_input_start:user_input_end]\n",
      "\u001b[31mAttributeError\u001b[39m: 'Testset' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "output_path = \"data/testset.json\"\n",
    "\n",
    "dataset.to_pandas().to_json()\n",
    "\n",
    "\n",
    "def sample_to_json(sample_str):\n",
    "    # Extract user_input and reference from the sample string\n",
    "    user_input_start = sample_str.find(\"user_input='\") + len(\"user_input='\")\n",
    "    user_input_end = sample_str.find(\"'\", user_input_start)\n",
    "    user_input = sample_str[user_input_start:user_input_end]\n",
    "    \n",
    "    reference_start = sample_str.find(\"reference='\") + len(\"reference='\")\n",
    "    reference_end = sample_str.find(\"'\", reference_start)\n",
    "    reference = sample_str[reference_start:reference_end]\n",
    "    \n",
    "    return {\"user_input\": user_input, \"reference\": reference}\n",
    "\n",
    "output_data = [sample_to_json(dataset) for data in dataset]\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"data/testset.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc670c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

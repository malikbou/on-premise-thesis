services:
  litellm:
    image: ghcr.io/berriai/litellm:main-stable
    ports:
      - "4000:4000"
    volumes:
      - ./config.yaml:/app/config.yaml:ro
    command: ["--config", "/app/config.yaml", "--port", "4000"]
    env_file:
      - .env
    container_name: litellm

  rag-api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./src:/app/src
      - rag_cache:/app/.rag_cache:ro
    depends_on:
      - litellm
    container_name: rag-api
    env_file:
      - .env
    environment:
      - INDEX_DIR=/app/.rag_cache/faiss_index

  index-builder:
    build: .
    command: ["python", "src/build_index.py"]
    volumes:
      - ./data:/app/data:ro
      - rag_cache:/app/.rag_cache
    env_file:
      - .env

  benchmarker:
    build: .
    command: ["python", "src/benchmark.py"]
    volumes:
      - ./testset:/app/testset:ro
      - ./results:/app/results
    depends_on:
      - rag-api
      - rag-api-minilm
      - rag-api-nomic
    environment:
      - EMBEDDING_API_MAP=all-minilm=http://rag-api-minilm:8000,nomic-embed-text=http://rag-api-nomic:8000
    env_file:
      - .env

  rag-api-minilm:
    build: .
    ports:
      - "8001:8000"
    volumes:
      - ./src:/app/src
      - rag_cache:/app/.rag_cache:ro
    depends_on:
      - litellm
    container_name: rag-api-minilm
    env_file:
      - .env
    environment:
      - INDEX_DIR=/app/.rag_cache/all_minilm/faiss_index
      - EMBEDDING_MODEL=all-minilm

  rag-api-nomic:
    build: .
    ports:
      - "8002:8000"
    volumes:
      - ./src:/app/src
      - rag_cache:/app/.rag_cache:ro
    depends_on:
      - litellm
    container_name: rag-api-nomic
    env_file:
      - .env
    environment:
      - INDEX_DIR=/app/.rag_cache/nomic_embed_text/faiss_index
      - EMBEDDING_MODEL=nomic-embed-text



volumes:
  rag_cache:
